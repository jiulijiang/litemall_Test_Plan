# 性能测试监控指标

## 1. 应用层监控指标

### 1.1 响应时间相关指标

- **平均响应时间(Average Response Time)**

  - 定义：所有请求响应时间的平均值
  - 监控工具：JMeter聚合报告
  - 预期标准：根据业务要求设定（如<2000ms）
  - 实际表现：在测试中发现，获取首页场景在10并发时平均响应时间为215ms，20并发时为452ms；商品搜索接口在30并发时平均响应时间为126ms；用户登录场景在15并发时平均响应时间为573ms
- **90%响应时间(90th Percentile)**

  - 定义：90%的请求响应时间不超过该值
  - 监控工具：JMeter聚合报告
  - 预期标准：根据业务要求设定（如<2500ms）
  - 实际表现：获取首页场景在20并发时90%响应时间为556ms；商品搜索接口在30并发时90%响应时间为157ms；用户登录场景在15并发时90%响应时间为661ms
- **95%响应时间(95th Percentile)**

  - 定义：95%的请求响应时间不超过该值
  - 监控工具：JMeter聚合报告
  - 预期标准：根据业务要求设定
  - 实际表现：获取首页场景在20并发时95%响应时间为595ms；商品搜索接口在30并发时95%响应时间为174ms；用户登录场景在15并发时95%响应时间为684ms
- **99%响应时间(99th Percentile)**

  - 定义：99%的请求响应时间不超过该值
  - 监控工具：JMeter聚合报告
  - 预期标准：根据业务要求设定
  - 实际表现：获取首页场景在20并发时99%响应时间为680ms；商品搜索接口在30并发时99%响应时间为221ms；用户登录场景在15并发时99%响应时间为729ms
- **最小响应时间(Min Response Time)**

  - 定义：所有请求中响应时间最短的值
  - 监控工具：JMeter聚合报告
- **最大响应时间(Max Response Time)**

  - 定义：所有请求中响应时间最长的值
  - 监控工具：JMeter聚合报告

### 1.2 吞吐量相关指标

- **每秒事务数(TPS - Transactions Per Second)**

  - 定义：系统每秒成功处理的事务数量
  - 监控工具：JMeter聚合报告
  - 预期标准：根据业务高峰期需求设定
  - 实际表现：获取首页场景在10并发时TPS达到峰值46，20并发时TPS为43.5；商品搜索接口在20并发时TPS达到峰值257.4，30并发时TPS降至231.3；用户登录场景在5并发时TPS为26.3，之后随并发增加TPS基本不变；混合业务场景在单用户时TPS为90.7，10并发时降至51
- **每秒请求数(Hits Per Second)**

  - 定义：系统每秒接收的请求数量
  - 监控工具：JMeter聚合报告
  - 实际表现：在各场景测试中，随着并发用户数增加，请求数相应增加，但在高并发下增长受限
- **每秒字节数(Bytes Per Second)**

  - 定义：系统每秒传输的数据量
  - 监控工具：JMeter聚合报告
  - 实际表现：在测试中未单独统计该指标，但可通过请求响应大小和TPS推算

### 1.3 错误率相关指标

- **错误率(Error Rate)**

  - 定义：失败请求数占总请求数的比例
  - 计算公式：错误率 = (失败请求数 / 总请求数) × 100%
  - 监控工具：JMeter聚合报告
  - 预期标准：< 0.1%
  - 实际表现：在所有测试场景中，错误率均为0，表明系统在功能正确性方面表现良好
- **HTTP错误状态码统计**

  - 定义：各类HTTP错误状态码出现的次数和比例
  - 监控工具：JMeter断言结果、查看结果树
  - 实际表现：在所有测试场景中，未出现HTTP错误状态码，所有请求均成功返回

### 1.4 并发相关指标

- **并发用户数(Concurrent Users)**

  - 定义：同时向系统发送请求的虚拟用户数
  - 监控工具：JMeter线程组设置
- **活跃线程数(Active Threads)**

  - 定义：当前正在执行请求的线程数
  - 监控工具：JMeter聚合报告

## 2. 系统资源监控指标

### 2.1 CPU使用率

- **CPU总体使用率**

  - 定义：CPU被使用的百分比
  - 监控工具：Windows性能监视器、Linux top命令、JMeter插件
  - 预期标准：< 80%
  - 实际表现：在测试中发现CPU资源严重不足，多个场景下CPU使用率接近或达到100%。获取首页场景在10并发时CPU使用率为66.2%，20并发时为64%；商品搜索接口在20并发时CPU使用率高达90.2%；用户登录场景在5并发时CPU使用率已达98.4%，10并发时为98.9%；混合业务场景在单用户时CPU使用率已高达87.2%，10并发时为93.9%
- **CPU各核心使用率**

  - 定义：多核CPU中每个核心的使用率
  - 监控工具：Windows性能监视器、Linux top命令
  - 实际表现：在测试中未单独统计各核心使用率，但总体CPU使用率已接近饱和，表明各核心负载较高

### 2.2 内存使用情况

- **内存使用率**

  - 定义：已使用内存占总内存的百分比
  - 监控工具：Windows性能监视器、Linux free命令、JMeter插件
  - 预期标准：< 80%
  - 实际表现：内存使用率在各测试场景中相对稳定，保持在33.5%-38.5%之间。获取首页场景在1并发时内存使用率为33.5%，20并发时为37.4%；商品搜索接口在各并发下内存使用率稳定在36.5%-37.4%；用户登录场景在各并发下内存使用率稳定在37.2%-37.8%；混合业务场景在各并发下内存使用率稳定在37.8%-38%；稳定性场景中内存使用率保持在38.5%左右
- **堆内存使用情况(JVM)**

  - 定义：Java应用堆内存的使用情况
  - 监控工具：JConsole、JVisualVM、JMeter插件
  - 实际表现：在测试中未单独统计该指标，但稳定性测试中系统在3小时12分钟后发生崩溃，可能与堆内存管理有关
- **非堆内存使用情况(JVM)**

  - 定义：Java应用非堆内存的使用情况
  - 监控工具：JConsole、JVisualVM、JMeter插件
  - 实际表现：在测试中未单独统计该指标

### 2.3 磁盘I/O指标

- **磁盘读写速度**

  - 定义：磁盘每秒读写字节数
  - 监控工具：Windows性能监视器、Linux iostat命令
  - 实际表现：在测试中未单独统计该指标，但稳定性测试中磁盘使用率保持在5%左右
- **磁盘使用率**

  - 定义：磁盘已使用空间占总空间的百分比
  - 监控工具：Windows资源监视器、Linux df命令
  - 实际表现：在稳定性测试中，磁盘使用率保持在5%左右，未出现明显增长
- **磁盘队列长度**

  - 定义：等待磁盘I/O操作的请求数
  - 监控工具：Windows性能监视器、Linux iostat命令
  - 实际表现：在测试中未单独统计该指标

### 2.4 网络指标

- **网络带宽使用率**

  - 定义：网络接口的带宽使用百分比
  - 监控工具：Windows性能监视器、Linux ifstat命令
  - 实际表现：在测试中未单独统计该指标，但测试环境网络带宽为1000Mbps，测试过程中未出现网络瓶颈
- **网络吞吐量**

  - 定义：网络接口每秒接收和发送的字节数
  - 监控工具：Windows性能监视器、Linux ifstat命令
  - 实际表现：在测试中未单独统计该指标
- **网络连接数**

  - 定义：当前建立的网络连接数量
  - 监控工具：Windows netstat命令、Linux netstat命令
  - 实际表现：在测试中未单独统计该指标，但系统在高并发下可能面临连接数限制问题

## 3. 数据库监控指标

### 3.1 数据库连接指标

- **活动连接数**

  - 定义：当前正在使用的数据库连接数
  - 监控工具：数据库监控工具、应用日志
  - 实际表现：在测试中未单独统计该指标，但系统在高并发下可能面临连接数限制问题
- **连接池使用率**

  - 定义：已使用连接数占连接池最大连接数的比例
  - 监控工具：应用监控、数据库监控工具
  - 实际表现：在测试中未单独统计该指标

### 3.2 数据库性能指标

- **SQL执行时间**

  - 定义：SQL语句的执行时间
  - 监控工具：数据库慢查询日志、APM工具
  - 实际表现：在测试报告中未详细分析该指标，但用户登录接口性能极差，可能存在数据库查询效率问题
- **查询吞吐量**

  - 定义：数据库每秒处理的查询数量
  - 监控工具：数据库监控工具
  - 实际表现：在测试中未单独统计该指标
- **缓存命中率**

  - 定义：数据库缓存命中的比例
  - 监控工具：数据库监控工具
  - 实际表现：在测试中未单独统计该指标，建议后续优化时引入缓存机制提高命中率

## 4. 应用服务器监控指标

### 4.1 Tomcat/Jetty等Web服务器指标

- **线程池使用情况**

  - 定义：Web服务器线程池中活跃线程和空闲线程的数量
  - 监控工具：JMX监控、APM工具
  - 实际表现：在测试中未单独统计该指标
- **请求处理时间**

  - 定义：Web服务器处理请求的时间
  - 监控工具：访问日志分析、APM工具
  - 实际表现：各场景请求处理时间差异较大，获取首页接口性能最佳，用户登录接口性能最差

### 4.2 应用性能监控(APM)指标

- **方法执行时间**

  - 定义：应用中关键方法的执行时间
  - 监控工具：APM工具（如SkyWalking、Pinpoint）
  - 实际表现：在测试中未使用APM工具进行详细监控
- **服务调用链路**

  - 定义：分布式系统中服务间的调用关系和耗时
  - 监控工具：APM工具
  - 实际表现：在测试中未使用APM工具进行链路追踪

## 5. 监控工具和方法

### 5.1 系统层监控工具

- Windows性能监视器(PerfMon)
- Linux top、iostat、free、df等命令
- JConsole、JVisualVM

### 5.2 应用层监控工具

- JMeter监控插件
- APM工具（如SkyWalking、Pinpoint等）
- 日志分析工具

### 5.3 数据库监控工具

- MySQL Workbench
- 数据库自带的监控视图
- 第三方监控工具

## 6. 采样策略

### 6.1 采样频率

- 系统资源指标：每秒采样一次
- 应用性能指标：每秒采样一次
- 数据库指标：每5秒采样一次

### 6.2 采样时长

- 基准测试：至少持续10分钟
- 负载测试：持续整个测试周期
- 稳定性测试：持续8小时以上

## 7. 告警阈值

### 7.1 性能指标阈值

- 平均响应时间：> 2000ms（根据测试报告，用户登录场景在5并发时已接近此阈值）
- 错误率：> 1%（根据测试报告，所有测试场景错误率均为0）
- TPS：根据业务需求设定（商品搜索接口性能最佳，20并发时TPS达257.4）

### 7.2 系统资源阈值

- CPU使用率：> 85%（根据测试报告，用户登录场景5并发时CPU使用率达98.4%，已超过阈值）
- 内存使用率：> 85%（根据测试报告，内存使用率在各测试场景中保持在33.5%-38.5%之间，未超过阈值）
- 磁盘使用率：> 90%（根据测试报告，稳定性测试中磁盘使用率保持在5%左右，未超过阈值）
