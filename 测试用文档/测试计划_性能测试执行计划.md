# 性能测试执行计划

## 1. 测试目标

对电商平台的核心业务场景进行性能测试，包括：

- 用户登录接口性能测试
- 商品搜索接口性能测试
- 提交订单接口性能测试
- 混合业务场景性能测试
- 峰值场景性能测试
- 稳定性场景性能测试

## 2. 测试范围

- **响应时间**：各接口在不同负载下的响应时间
- **吞吐量**：系统每秒处理的请求数（TPS）
- **并发用户数**：系统能支持的最大并发用户数
- **资源利用率**：服务器CPU、内存、网络等资源使用情况
- **错误率**：请求失败比例
- **系统稳定性**：长时间运行下的系统稳定性表现

## 3. 测试环境

### 3.1 硬件环境

- 测试机：Windows 11 64位，Intel i7，32GB内存
- 应用服务器：CentOS 7.9 64位，虚拟4核CPU，8GB内存
- 数据库服务器：CentOS 7.9 64位，虚拟4核CPU，8GB内存

### 3.2 软件环境

- 操作系统版本：CentOS 7.9 64位
- 应用服务器版本：Tomcat 8.5
- 数据库版本：MySQL 5.7
- JDK版本：JDK 1.8
- 测试工具：Apache JMeter 5.6.3

## 4. 测试场景设计

### 4.1 用户登录场景

- **测试数据**：使用已注册用户账号(user0001-user0100)，存储在userlogin.csv文件中
- **负载模式**：逐步增加并发用户数(1, 5, 10, 15, 20)
- **测试指标**：响应时间、TPS、错误率、CPU使用率、内存使用率

### 4.2 商品搜索场景

- **测试数据**：使用不同关键词进行搜索(母亲, 母亲节, 父亲节等)
- **负载模式**：逐步增加并发用户数(1, 5, 10, 15, 20, 30)
- **测试指标**：响应时间、TPS、错误率、CPU使用率、内存使用率

### 4.3 购物车操作场景

- **测试数据**：添加不同商品到购物车(goodsId: 1181000, number: 1-200)
- **负载模式**：逐步增加并发用户数(1, 5, 10, 15)
- **测试指标**：响应时间、TPS、错误率、CPU使用率、内存使用率

### 4.4 提交订单场景

- **测试数据**：使用有效的地址ID和购物车ID进行订单提交
- **负载模式**：逐步增加并发用户数(1, 5, 10, 15)
- **测试指标**：响应时间、TPS、错误率、CPU使用率、内存使用率

### 4.5 混合业务场景

- **测试数据**：包含完整的用户购物流程，使用参数化账号数据
- **负载模式**：逐步增加并发用户数(1, 3, 5, 10, 15)
- **测试流程**：
  1. 获取首页数据（`/wx/home/index`）
  2. 商品搜索（`/wx/goods/list`），搜索关键词"母亲节"，并提取商品ID
  3. 用户登录（`/wx/auth/login`），使用参数化的账号密码，获取登录token
  4. 加入购物车（`/wx/cart/add`），使用提取的商品ID和登录token
- **测试指标**：响应时间、TPS、错误率、CPU使用率、内存使用率

### 4.6 峰值场景

- **测试数据**：模拟系统在短时间内承受高并发请求的情况
- **负载模式**：快速加压至峰值并发(30, 50)
- **持续时间**：1-3分钟
- **测试指标**：最大TPS、峰值响应时间、错误率变化、资源峰值使用情况、系统恢复能力

### 4.7 稳定性场景

- **测试数据**：使用低负载进行长时间测试
- **负载模式**：持续5并发用户
- **持续时间**：8小时
- **测试指标**：响应时间稳定性、错误率累积、资源使用趋势（CPU、内存、磁盘I/O）、内存泄漏检测

## 5. 测试执行步骤

1. 环境准备和配置检查
2. JMeter脚本准备和验证
3. 执行单用户基准测试
4. 执行登录接口性能测试
5. 执行商品搜索接口性能测试
6. 执行购物车操作接口性能测试
7. 执行提交订单接口性能测试
8. 执行混合业务场景性能测试
9. 执行峰值场景性能测试
10. 执行稳定性场景性能测试
11. 监控系统资源使用情况
12. 收集和分析测试结果

## 6. 测试监控指标

- **响应时间**：平均响应时间、90%响应时间、95%响应时间、99%响应时间
- **吞吐量**：每秒事务数(TPS)
- **错误率**：请求失败比例
- **并发用户数**：同时在线用户数
- **系统资源**：CPU使用率、内存使用率、磁盘I/O、网络流量
- **稳定性指标**：长时间运行下的资源使用趋势、错误率累积情况

## 7. 测试准入标准

- 测试环境已搭建完成并验证
- 测试数据已准备完毕（100个测试账号）
- JMeter脚本已开发并验证
- 监控工具已部署
- 基准测试已通过验证

## 8. 测试准出标准

- 所有测试场景均已执行完毕
- 测试结果已收集和分析
- 性能指标达到预期要求：
  - 单用户基准响应时间 < 500ms
  - 90%请求响应时间 < 2000ms
  - 错误率 < 0.1%
  - CPU使用率 < 80%
  - 内存使用率 < 80%
- 稳定性测试通过（8小时无崩溃）
- 测试报告已编写完成并通过评审

## 9. 风险和应对措施

- **环境不稳定风险**：测试过程中可能出现服务器宕机、网络中断等问题

  - 应对措施：提前检查环境稳定性，准备备用环境，定期备份测试数据
- **测试数据不足风险**：测试数据量不足可能影响测试结果的准确性

  - 应对措施：准备充足的测试数据（100个账号），并进行数据验证
- **脚本执行异常风险**：JMeter脚本可能因参数配置错误导致执行异常

  - 应对措施：执行前进行脚本验证，准备调试方案，记录执行日志
- **结果分析偏差风险**：可能因监控工具问题或数据分析方法不当导致结果偏差

  - 应对措施：使用多种监控工具交叉验证，采用标准化分析方法，进行结果复核
- **性能瓶颈识别风险**：可能遗漏关键性能瓶颈点

  - 应对措施：全面覆盖各业务场景，重点关注资源使用率，进行深度性能分析
- **稳定性测试失败风险**：系统可能无法通过长时间稳定性测试

  - 应对措施：提前进行短时间稳定性验证，准备问题排查方案，实时监控系统状态

## 10. 人员分工

- **测试工程师**：

  - 负责测试方案设计和测试用例编写
  - 负责JMeter脚本开发和调试
  - 负责测试执行和监控
  - 负责测试结果分析和报告编写
- **开发团队**：

  - 负责测试环境搭建和维护
  - 负责协助解决测试过程中发现的系统问题
  - 负责性能优化方案的实施
- **运维团队**：

  - 负责服务器资源监控和调配
  - 负责系统日志收集和分析
  - 负责协助排查系统稳定性问题

## 11. 时间安排

- **测试准备阶段**：2个工作日

  - 环境搭建和验证：1个工作日
  - 测试数据准备和脚本开发：1个工作日
- **测试执行阶段**：5个工作日

  - 单用户基准测试：0.5个工作日
  - 各接口场景测试：2个工作日
  - 混合业务场景测试：1个工作日
  - 峰值场景测试：0.5个工作日
  - 稳定性场景测试：1个工作日
- **结果分析阶段**：1个工作日

  - 测试结果收集和分析
  - 性能瓶颈识别和问题定位
- **报告编写阶段**：1个工作日

  - 测试报告编写和评审
