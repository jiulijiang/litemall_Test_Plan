# 轻商城litemall接口测试计划

- 文档编号： [TP-LCM-001]
- 版本： 1.0
- 编写日期： 2025.9.10
- 编写人： 测试工程师
- 审核人： 

## 1. 测试目的
本测试计划旨在通过系统化的接口测试、UI测试及性能测试，全面验证轻商城系统的功能完整性、用户体验及性能表现：
- 接口测试：验证系统各接口的功能正确性、数据准确性、安全性及稳定性，确保接口按照需求规范正确实现
- UI测试：验证系统界面的功能完整性、用户交互流畅性、响应及时性及视觉一致性
- 性能测试：评估系统在不同负载条件下的响应时间、吞吐量、并发处理能力及资源利用率
- 自动化测试：实现60%核心功能的自动化测试，提高测试效率，确保系统持续稳定运行
通过全面测试，确保轻商城系统满足业务需求，提升用户体验，保障系统上线后的稳定运行。
## 2. 测试范围
根据需求文档[RD-LCM-001]和API文档，本次测试覆盖以下模块和功能点，包括接口测试、UI测试及性能测试：

### 2.1 接口测试范围
#### 2.1.1 用户认证模块
- 注册功能：手机号、用户名、密码、确认密码、验证码的输入验证（自动化测试）
- 登录功能：手机号、密码的输入验证及token返回（自动化测试）

#### 2.1.2 商品搜索模块
- 商品搜索功能：关键词搜索、搜索结果排序、搜索历史记录（自动化测试）

#### 2.1.3 购物车模块
- 加入购物车功能：商品id、购买数量、产品id的输入验证（自动化测试）

#### 2.1.4 地址管理模块
- 添加收货地址功能：姓名、手机号、地区信息、详细地址等字段验证

#### 2.1.5 订单管理模块
- 提交订单功能：地址选择、购物车商品选择、优惠券使用、订单备注等（自动化测试）

### 2.2 UI测试范围
#### 2.2.1 用户认证模块
- 注册页面：表单验证、错误提示、成功跳转
- 登录页面：表单验证、错误提示、成功跳转（自动化测试）

#### 2.2.2 商品搜索模块
- 搜索框：输入提示、搜索按钮交互、搜索结果展示

#### 2.2.3 购物车模块
- 购物车页面：商品展示、数量调整、删除商品

#### 2.2.4 地址管理模块
- 地址管理页面：地址列表展示、添加/编辑/删除地址功能（自动化测试）

#### 2.2.5 订单管理模块
- 订单确认页面：商品清单、收货信息、支付方式选择
- 订单列表页面：订单状态展示、订单详情查看（自动化测试）

### 2.3 性能测试范围
#### 2.3.1 核心接口性能
- 登录接口：响应时间、吞吐量测试
- 商品搜索接口：响应时间、吞吐量测试
- 提交订单接口：响应时间、并发处理能力测试

#### 2.3.2 系统负载测试
- 模拟多用户并发访问下的系统性能表现
- 长时间运行下的系统稳定性测试

### 2.4 自动化测试覆盖
- 接口测试：60%的核心功能（登录、注册、商品搜索、加入购物车、提交订单）
- UI测试：60%的核心功能（登录、地址管理、订单列表）

## 3. 测试人员安排
| 序号 | 角色 | 职责 | 时间 | 产出内容 |
|------|------|------|------|----------|
| 01 | 测试负责人 | 测试计划制定、进度跟踪、报告汇总、资源协调 | 7天 | 1. 测试计划<br>2. 测试总结报告<br>3. 缺陷统计报告 |
| 02 | 接口测试工程师 | 接口测试用例编写、执行、缺陷提交 | 7天 | 1. 接口测试点(Xmind)<br>2. 接口测试用例(Excel)<br>3. 接口自动化脚本(Python)<br>4. 接口测试报告 |
| 03 | UI测试工程师 | UI测试用例编写、执行、缺陷提交 | 7天 | 1. UI测试点(Xmind)<br>2. UI测试用例(Excel)<br>3. UI自动化脚本<br>4. UI测试报告 |
| 04 | 性能测试工程师 | 性能测试场景设计、执行、分析 | 5天 | 1. 性能测试脚本<br>2. 性能测试报告 |

## 4. 测试进度安排
| 阶段 | 时间安排 | 主要任务 | 责任人 |
|------|----------|----------|--------|
| **测试准备阶段** | 第1天 | 1. 需求分析与理解<br>2. 测试环境搭建与验证<br>3. 测试工具安装与配置<br>4. 测试数据准备<br>5. 测试团队培训 | 测试负责人、全体测试工程师 |
| **测试用例设计阶段** | 第2-3天 | 1. 测试点拆分与分析(Xmind)<br>2. 接口测试用例编写<br>3. UI测试用例编写<br>4. 性能测试场景设计<br>5. 测试用例评审 | 测试负责人、接口测试工程师、UI测试工程师、性能测试工程师 |
| **自动化测试开发阶段** | 第4-5天 | 1. 接口自动化脚本开发(Python+pytest+requests)<br>2. UI自动化脚本开发<br>3. 自动化脚本调试与验证 | 接口测试工程师、UI测试工程师 |
| **测试执行阶段** | 第6-8天 | 1. 接口功能测试执行<br>2. UI功能测试执行<br>3. 性能测试执行<br>4. 自动化测试执行<br>5. 缺陷记录与跟踪 | 接口测试工程师、UI测试工程师、性能测试工程师 |
| **测试报告阶段** | 第9天 | 1. 测试结果汇总与分析<br>2. 缺陷统计与分析<br>3. 测试报告编写<br>4. 测试总结会议 | 测试负责人、全体测试工程师 |
| **总计** | 9天 | 完成全部测试工作 | 全体测试团队 |

## 5. 测试资源
### 5.1 硬件资源
| 资源类型 | 配置 | 数量 | 用途 |
|---------|------|------|------|
| 测试主机 | 32G内存、3000G硬盘、i7处理器 | 1台 | 运行测试工具、执行自动化测试 |
| 虚拟机 | 16G内存、500G硬盘、4核CPU | 1台 | 部署测试环境、运行被测系统 |
| 网络设备 | 千兆交换机 | 1台 | 保证测试环境网络稳定性 |

### 5.2 软件资源
| 工具名称 | 版本/说明 | 用途 | 负责人 |
|---------|-----------|------|--------|
| Postman | 9.0+ | 接口测试执行与调试 | 接口测试工程师 |
| Excel | 2019 | 测试用例和缺陷报告的编写 | 全体测试工程师 |
| DataGrip | 2023.2+ | 数据库操作和查询 | 接口测试工程师 |
| Python | 3.10+ | 自动化测试脚本开发 | 接口测试工程师、UI测试工程师 |
| pytest | 7.0+ | 测试框架，用于组织和执行测试 | 接口测试工程师 |
| requests | 2.28+ | HTTP客户端库，用于接口测试 | 接口测试工程师 |
| Selenium/Appium | 4.0+ | UI自动化测试工具 | UI测试工程师 |
| Xmind | 8 | 测试点的拆分分析 | 全体测试工程师 |
| JMeter | 5.5+ | 性能测试工具，用于负载和压力测试 | 性能测试工程师 |
| Allure Report | 2.15+ | 生成可视化测试报告 | 接口测试工程师、UI测试工程师 |
| Git | 2.30+ | 版本控制工具，管理测试代码 | 全体测试工程师 |

### 5.3 文档资源
| 文档名称 | 版本 | 用途 | 来源 |
|---------|------|------|------|
| 需求规格说明书 | 1.0 | 了解系统功能需求 | 产品经理 |
| 轻商城项目-API文档 | 1.0 | 接口测试的主要依据 | 开发团队 |
| 业务流程图.md | 1.0 | 了解业务逻辑和流程 | 产品经理 |
| 测试用例模板 | 内部标准 | 规范测试用例编写 | 测试团队 |
| 缺陷报告模板 | 内部标准 | 规范缺陷提交流程 | 测试团队 |
| 测试计划模板 | 内部标准 | 规范测试计划编写 | 测试团队 |

## 6. 测试环境
### 6.1 操作系统环境
| 环境类型 | 操作系统 | 版本 | 位数 | 用途 |
|---------|---------|------|------|------|
| 测试主机 | Windows | 11 | 64位 | 运行测试工具、执行自动化测试 |
| 虚拟机 | CentOS | 7.9 | 64位 | 部署被测系统服务端 |
| 数据库服务器 | Ubuntu | 22.04 | 64位 | 运行MySQL数据库 |

### 6.2 网络环境
| 网络类型 | 带宽 | IP地址范围 | 用途 |
|---------|------|----------|------|
| 局域网 | 100Mbps | 192.168.1.0/24 | 测试团队内部通信 |
| 外部网络 | 100Mbps | 动态分配 | 访问外部资源、测试系统公网访问 |

### 6.3 测试目标系统
| 系统类型 | 访问地址 | 端口 | 描述 |
|---------|---------|------|------|
| 轻商城前台系统 | http://www.litemall360.com:8082 | 8082 | 用户访问的主要入口，提供购物功能 |
| 轻商城后台管理系统 | http://www.litemall360.com:8081 | 8081 | 管理员操作的后台界面，用于系统管理 |
| MySQL数据库 | 192.168.1.100 | 3306 | 存储系统所有业务数据 |

### 6.4 测试环境配置要求
- 确保测试环境与生产环境配置保持一致或相似
- 测试环境应独立于开发环境和生产环境
- 定期备份测试环境数据，确保测试数据的可恢复性
- 保证测试环境网络稳定，避免网络波动影响测试结果

## 7. 测试策略
### 7.1 测试方法
#### 7.1.1 接口测试方法
- **功能测试**：验证各接口的基本功能是否按照需求正确实现，包括正常流程和异常流程
- **边界值测试**：测试输入参数的边界值（如手机号长度、密码长度等），确保接口在极端情况下的稳定性
- **等价类划分测试**：将输入数据划分为有效等价类和无效等价类，从每个等价类中选取代表性数据进行测试
- **参数组合测试**：测试不同参数组合下接口的表现
- **安全测试**：检查接口是否存在SQL注入、XSS、未授权访问等安全漏洞
- **接口自动化测试**：利用Python+pytest+requests框架实现接口的自动化测试，覆盖60%的核心功能

#### 7.1.2 UI测试方法
- **功能测试**：验证界面功能是否按照需求正确实现，包括页面元素展示、用户交互等
- **兼容性测试**：测试系统在不同浏览器（Chrome、Firefox、Edge等）和分辨率下的兼容性
- **用户体验测试**：评估系统的易用性、界面美观度、响应速度等用户体验指标
- **UI自动化测试**：使用Selenium/Appium工具实现UI的自动化测试，覆盖60%的核心功能

#### 7.1.3 性能测试方法
- **负载测试**：模拟不同用户负载下，系统的响应时间、吞吐量等性能指标
- **压力测试**：测试系统在极限负载下的稳定性和可靠性
- **并发测试**：测试系统在多用户并发访问下的表现
- **稳定性测试**：测试系统在长时间运行下的稳定性

### 7.2 测试用例设计原则
- **全面性**：覆盖所有功能点、API接口和业务流程
- **有效性**：测试用例应能够有效地发现缺陷
- **可重复性**：测试用例应具有良好的可重复性，确保测试结果的一致性
- **独立性**：每个测试用例应相对独立，尽量减少测试用例之间的依赖
- **可追溯性**：测试用例应与需求文档中的功能点保持可追溯
- **经济性**：在保证测试覆盖的前提下，尽量减少测试用例的数量

### 7.3 测试用例设计方法
- **等价类划分法**：将输入数据划分为有效等价类和无效等价类，从每个等价类中选取代表性数据
- **边界值分析法**：针对输入参数的边界值（最小值、最大值、边界点附近的值）设计测试用例
- **场景法**：根据业务流程设计测试场景，覆盖完整的业务流程
- **错误推测法**：基于经验和直觉推测系统可能出现的错误，设计针对性的测试用例
- **因果图法**：用于分析输入条件之间的组合关系和输出结果之间的依赖关系

### 7.4 测试执行流程
#### 7.4.1 接口测试执行流程
1. 准备测试环境和测试数据
2. 执行接口自动化测试脚本，获取初始测试结果
3. 针对自动化测试未覆盖的功能点，执行手工测试
4. 记录测试结果，包括成功/失败状态、实际响应等信息
5. 发现缺陷时，及时在缺陷管理系统中记录，并通知开发团队
6. 跟踪缺陷修复情况，对修复后的缺陷进行回归测试

#### 7.4.2 UI测试执行流程
1. 准备测试环境和测试数据
2. 在不同浏览器和分辨率下执行UI自动化测试脚本
3. 针对自动化测试未覆盖的功能点，执行手工UI测试
4. 记录测试结果，包括成功/失败状态、界面截图等信息
5. 发现缺陷时，及时在缺陷管理系统中记录，并通知开发团队
6. 跟踪缺陷修复情况，对修复后的缺陷进行回归测试

#### 7.4.3 性能测试执行流程
1. 准备性能测试环境和测试数据
2. 使用JMeter工具设计并开发性能测试脚本
3. 执行性能测试，逐步增加用户负载
4. 监控系统资源使用情况（CPU、内存、磁盘I/O等）
5. 收集并分析性能测试数据，生成性能测试报告
6. 针对性能瓶颈提出优化建议

### 7.5 自动化测试策略
- **自动化范围**：覆盖60%的核心功能，包括登录、注册、商品搜索、加入购物车、提交订单等接口测试，以及登录、地址管理、订单列表等UI测试
- **自动化工具**：接口自动化使用Python+pytest+requests框架，UI自动化使用Selenium/Appium工具
- **自动化脚本管理**：使用Git进行版本控制，确保脚本的可维护性
- **自动化测试执行**：定期执行自动化测试脚本，确保系统功能的稳定性
- **测试报告生成**：使用Allure Report生成可视化的测试报告，直观展示测试结果

## 8. 测试工具
| 工具名称 | 版本/说明 | 用途 | 测试类型 | 负责人 |
|----------|-----------|------|----------|--------|
| Postman | 9.0+ | 发送HTTP请求，验证接口响应，进行接口手工测试 | 接口测试 | 接口测试工程师 |
| Python+pytest+requests | 3.8+ | 编写和执行接口自动化测试用例，实现接口的自动化测试 | 接口测试（自动化） | 接口测试工程师 |
| Selenium | 4.0+ | 模拟浏览器操作，进行Web UI自动化测试 | UI测试（自动化） | UI测试工程师 |
| Appium | 2.0+ | 模拟移动设备操作，进行移动端UI自动化测试 | UI测试（自动化） | UI测试工程师 |
| JMeter | 5.4+ | 设计和执行性能测试脚本，模拟高并发访问 | 性能测试 | 性能测试工程师 |
| Allure Report | 2.17+ | 生成可视化的测试报告，直观展示测试结果 | 自动化测试 | 测试负责人 |
| Excel | 2019 | 记录测试用例和测试结果，进行测试数据管理 | 通用 | 所有测试人员 |
| DataGrip | 2022+ | 数据库操作和查询，验证数据库数据是否正确，进行数据准备和清理 | 通用 | 所有测试人员 |
| Xmind | 8 | 测试点的拆分分析，进行测试需求分析和测试用例设计 | 通用 | 测试负责人 |
| Git | 2.30+ | 版本控制，管理测试脚本和测试文档 | 自动化测试 | 所有测试人员 |

## 9. 风险与标准
### 9.1 测试风险
#### 9.1.1 环境风险
- **测试环境问题**：虚拟机性能不足可能影响测试效率和准确性
- **环境配置问题**：测试环境与生产环境配置不一致，可能导致测试结果不准确
- **网络环境问题**：网络不稳定可能导致接口测试失败

#### 9.1.2 数据风险
- **测试数据问题**：测试数据准备不充分可能导致测试覆盖不全
- **数据一致性问题**：测试过程中数据被修改，可能影响测试结果的准确性
- **数据安全问题**：测试数据可能包含敏感信息，存在数据泄露风险

#### 9.1.3 资源风险
- **测试人员不足**：测试团队人员不足可能导致测试进度延迟
- **测试工具问题**：测试工具选型不当或使用不熟练，可能影响测试效率
- **测试设备问题**：测试设备故障可能导致测试中断

#### 9.1.4 需求风险
- **需求变更**：需求频繁变更可能导致测试用例失效，需要重新设计和执行
- **需求不明确**：需求文档不清晰或存在歧义，可能导致测试理解错误

#### 9.1.5 技术风险
- **技术复杂性**：系统技术架构复杂，可能导致测试难度增加
- **自动化测试脚本维护**：自动化测试脚本需要持续维护，否则可能失效

### 9.2 应对措施
#### 9.2.1 环境风险应对措施
- 提前准备多套测试环境，确保虚拟机资源充足
- 建立环境配置文档，确保测试环境与生产环境配置一致
- 使用网络监控工具，及时发现和解决网络问题
- 定期备份测试环境，以便快速恢复

#### 9.2.2 数据风险应对措施
- 制定详细的测试数据准备计划，确保测试数据覆盖各种场景
- 建立测试数据管理机制，确保测试数据的一致性
- 对敏感测试数据进行加密或匿名化处理
- 测试前和测试后进行数据备份和清理

#### 9.2.3 资源风险应对措施
- 合理分配测试任务，充分利用测试团队资源
- 提前培训测试人员，确保测试工具使用熟练
- 准备备用测试设备，确保测试不会因设备故障中断

#### 9.2.4 需求风险应对措施
- 加强需求沟通，确保需求理解一致
- 建立需求变更管理流程，及时更新测试计划和测试用例
- 对需求文档进行评审，确保需求清晰明确

#### 9.2.5 技术风险应对措施
- 组织技术培训，提高测试团队的技术能力
- 建立自动化测试脚本维护机制，定期更新脚本
- 采用模块化设计，提高自动化测试脚本的可维护性

### 9.3 测试标准
#### 9.3.1 接口测试标准
- **响应时间标准**：接口响应时间应小于1秒，90%的请求响应时间应小于500毫秒
- **成功率标准**：接口请求成功率应达到99.9%以上
- **错误码标准**：错误码应规范统一，且有详细的错误描述
- **安全性标准**：接口应通过安全测试，不存在SQL注入、XSS等安全漏洞

#### 9.3.2 UI测试标准
- **页面加载时间**：页面加载时间应小于3秒
- **兼容性标准**：系统应在主流浏览器（Chrome、Firefox、Edge等）和分辨率下正常显示和运行
- **用户体验标准**：界面应友好易用，符合用户习惯

#### 9.3.3 性能测试标准
- **响应时间标准**：在预期用户负载下，系统响应时间应满足业务要求
- **吞吐量标准**：系统应能处理预期的并发请求量
- **资源使用率标准**：系统资源（CPU、内存、磁盘I/O等）使用率应在合理范围内
- **稳定性标准**：系统在长时间运行下应保持稳定，无内存泄漏等问题

## 10. 准入准出标准
### 10.1 准入标准
#### 10.1.1 环境准入标准
- **测试环境搭建完成**：网络、数据库、应用服务正常运行
- **环境配置符合要求**：测试环境与生产环境配置一致（如操作系统版本、数据库版本、中间件版本等）
- **环境验证通过**：通过基础功能测试验证测试环境可用

#### 10.1.2 工具准入标准
- **测试工具安装配置完毕**：Postman、Python、Selenium、JMeter等测试工具安装配置完成
- **工具验证通过**：工具可以正常使用，如Postman可以正常发送请求，Python脚本可以正常运行
- **自动化测试框架搭建完成**：接口自动化和UI自动化测试框架搭建完成

#### 10.1.3 文档准入标准
- **测试用例编写完成并通过评审**：测试用例覆盖率达到100%，且通过测试负责人和开发团队评审
- **测试计划编写完成**：测试计划文档已经编写完成并通过评审
- **需求文档和API文档齐全**：项目需求文档和API文档完整可用

#### 10.1.4 数据准入标准
- **测试数据准备完毕**：覆盖正常场景、异常场景、边界值等各种测试场景的测试数据准备完成
- **测试数据验证通过**：测试数据的准确性和完整性已验证
- **测试数据备份完成**：测试开始前已对测试数据进行备份

#### 10.1.5 人员准入标准
- **测试人员已熟悉项目需求和测试流程**：测试团队成员已参加需求培训和测试流程培训
- **测试人员已掌握测试工具使用方法**：测试团队成员已掌握Postman、Python、Selenium等测试工具的使用方法
- **测试团队沟通机制建立**：测试团队内部及与开发团队、产品团队的沟通机制已建立

### 10.2 准出标准
#### 10.2.1 测试执行准出标准
- **所有测试用例执行完毕**：接口测试、UI测试、性能测试的所有测试用例均已执行完毕
- **测试覆盖率达到100%**：功能点覆盖率和API接口覆盖率均达到100%
- **自动化测试通过率达到95%以上**：自动化测试用例通过率应达到95%以上
- **测试结果记录完整**：测试结果记录完整，包括测试执行时间、执行人员、测试状态、实际结果等信息

#### 10.2.2 缺陷修复准出标准
- **严重缺陷已全部修复并验证通过**：优先级为高的缺陷已全部修复，并通过回归测试验证
- **一般缺陷修复率达到90%以上**：优先级为中的缺陷修复率应达到90%以上
- **轻微缺陷修复率达到70%以上**：优先级为低的缺陷修复率应达到70%以上
- **遗留缺陷已获得批准**：未修复的缺陷已获得产品负责人或项目负责人的批准

#### 10.2.3 报告准出标准
- **测试报告编写完成并通过评审**：测试报告已编写完成，内容包括测试执行情况、缺陷统计、测试结论和建议等，并通过测试负责人和项目负责人评审
- **缺陷报告完整**：缺陷报告内容完整，包括缺陷描述、复现步骤、预期结果、实际结果、截图等信息
- **自动化测试报告生成**：使用Allure Report生成自动化测试报告

#### 10.2.4 文档归档准出标准
- **测试过程中使用的文档、工具、数据已归档**：测试计划、测试用例、测试报告、缺陷报告、测试脚本、测试数据等均已归档
- **归档文档可追溯**：归档文档应具有良好的可追溯性，便于后续查阅和使用
- **归档文档存储安全**：归档文档存储在安全的位置，防止丢失和泄露

## 11. 附录
### 11.1 测试术语和缩略词
| 术语/缩略词 | 英文全称 | 中文解释 |
|------------|----------|---------|
| API | Application Programming Interface | 应用程序编程接口 |
| UI | User Interface | 用户界面 |
| HTTP | HyperText Transfer Protocol | 超文本传输协议 |
| JSON | JavaScript Object Notation | JavaScript对象表示法 |
| SQL | Structured Query Language | 结构化查询语言 |
| XSS | Cross-Site Scripting | 跨站脚本攻击 |
| Pytest | Python Testing Framework | Python测试框架 |
| Selenium | Selenium WebDriver | Web自动化测试工具 |
| Appium | - | 移动端自动化测试工具 |
| JMeter | Apache JMeter | 性能测试工具 |
| CI/CD | Continuous Integration/Continuous Deployment | 持续集成/持续部署 |

### 11.2 参考文档
| 文档名称 | 版本 | 作者/来源 | 用途 |
|---------|------|----------|------|
| 需求文档.md | v1.0 | 产品团队 | 描述系统功能需求 |
| 业务流程图.md | v1.0 | 产品团队 | 描述系统业务流程 |
| API文档.md | v1.0 | 开发团队 | 描述系统API接口规范 |
| 测试计划.md | v1.0 | 测试团队 | 指导测试工作的执行 |
| 测试用例.md | v1.0 | 测试团队 | 描述具体的测试用例 |

### 11.3 测试数据管理
- **测试数据分类**：正常数据、异常数据、边界数据、随机数据等
- **测试数据生成方法**：手动创建、脚本生成、数据导入等
- **测试数据清理策略**：测试前备份、测试后清理、定期清理等
- **测试数据安全措施**：敏感数据加密、匿名化处理、访问控制等

### 11.4 沟通机制
- **每日站会**：测试团队每天早上举行站会，汇报测试进度和遇到的问题
- **周会**：测试团队每周举行一次例会，总结本周测试工作，计划下周工作
- **缺陷评审会议**：定期举行缺陷评审会议，讨论缺陷优先级和修复策略
- **测试报告评审会议**：测试报告编写完成后，举行评审会议，确保报告质量

### 11.5 测试模板
#### 11.5.1 测试用例模板
| 字段 | 说明 |
|------|------|
| 测试用例ID | 唯一标识测试用例 |
| 测试模块 | 所属的测试模块 |
| 测试点 | 具体的测试点 |
| 测试步骤 | 详细的测试步骤 |
| 预期结果 | 期望的测试结果 |
| 实际结果 | 实际的测试结果 |
| 测试状态 | 通过/失败/阻塞 |
| 测试人员 | 执行测试的人员 |
| 测试时间 | 执行测试的时间 |
| 备注 | 其他需要说明的信息 |

#### 11.5.2 缺陷报告模板
| 字段 | 说明 |
|------|------|
| 缺陷ID | 唯一标识缺陷 |
| 缺陷标题 | 缺陷的简要描述 |
| 缺陷描述 | 缺陷的详细描述 |
| 复现步骤 | 复现缺陷的详细步骤 |
| 预期结果 | 期望的结果 |
| 实际结果 | 实际的结果 |
| 缺陷截图 | 缺陷的截图 |
| 缺陷优先级 | 高/中/低 |
| 缺陷状态 | 新建/已分配/已修复/已验证/已关闭 |
| 发现人 | 发现缺陷的人员 |
| 发现时间 | 发现缺陷的时间 |
| 修复人 | 修复缺陷的人员 |
| 修复时间 | 修复缺陷的时间 |
| 备注 | 其他需要说明的信息 |

